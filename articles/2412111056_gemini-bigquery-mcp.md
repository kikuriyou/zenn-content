---
title: "Gemini 2.0 Flash ã‹ã‚‰ MCP ã‚’åˆ©ç”¨ã—ã¦ BigQuery ã‚’æ“ä½œã™ã‚‹"
emoji: "ğŸ€"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["googlecloud", "vertexai", "gemini", "bigquery", "mcp"]
published: false
publication_name: hogeticlab
---

[Google Cloud Champion Innovators Advent Calendar 2024](https://adventar.org/calendars/10061) ã® 12 æ—¥ç›®ã®è¨˜äº‹ã§ã™ã€‚


# ã¯ã˜ã‚ã«
LLM ãŒåºƒãæ™®åŠã—ã€æ´»ç”¨ç¯„å›²ãŒæ€¥é€Ÿã«æ‹¡å¤§ã—ã¦ããŸã“ã¨ã§ã€ãƒ„ãƒ¼ãƒ«é€£æºæ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸ AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹æ©Ÿä¼šã‚‚å¢—ãˆã¦ãã¦ã„ã¾ã™ã€‚ã“ã®ã‚ˆã†ãª LLM ã¨ãƒ„ãƒ¼ãƒ«ã®é€£æºã«ã‚ˆã‚Šã€ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‹ã‚‰æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ ã‚„ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆ¶å¾¡ãƒ»è‡ªå‹•åŒ–ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
ã—ã‹ã—ã€AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã«ã¯2ã¤ã®å›°ã‚Šã”ã¨ãŒã‚ã‚‹ã¨æ„Ÿã˜ã¦ã„ã¾ã™ã€‚1ã¤ç›®ã¯ã€è¤‡é›‘ãªæŒ‡ç¤ºã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«å¿…è¦ãªé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”é€Ÿåº¦ãŒé…ã„ç‚¹ã€2ã¤ç›®ã¯è¤‡æ•°ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ãƒ„ãƒ¼ãƒ«ã‚’å†åˆ©ç”¨ã™ã‚‹éš›ã®å®Ÿè£…åŠ¹ç‡ã®å•é¡Œã§ã™ã€‚
æœ¬è¨˜äº‹ã§ã¯ã€ã“ã‚Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã®ä¸€ä¾‹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚LLM ã‹ã‚‰ BigQuery ã‚’æ“ä½œã™ã‚‹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ãŠã„ã¦ã€Gemini 2.0 Flash ã‚’åˆ©ç”¨ã—ã¦æ¤œè¨¼ã‚’é«˜é€ŸåŒ–ã—ãªãŒã‚‰ã€MCPï¼ˆModel Context Protocolï¼‰ã‚’æ´»ç”¨ã—ã¦ãƒ„ãƒ¼ãƒ«å®Ÿè£…ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ã“ã¨ã‚’è©¦ã¿ã¾ã™ã€‚


# Gemini 2.0 Flash ã¨ã¯
Gemini 2.0 Flash ã¯ã€ã¡ã‚‡ã†ã©æ˜¨æ—¥ã‹ã‚‰ä»Šæ—¥ã«ã‹ã‘ã¦ç™ºè¡¨ã•ã‚ŒãŸ Gemini ã‚·ãƒªãƒ¼ã‚ºã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚[ç™ºè¡¨](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#gemini-2-0-flash)ã«ã‚ˆã‚‹ã¨ã€ã“ã‚Œã¾ã§ã® Gemini 1.5 Flash ã¨åŒæ§˜ã«é«˜é€Ÿã§ã‚ã‚ŠãªãŒã‚‰ã€å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã§ Gemini 1.5 Pro ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã¾ãŸã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ã€è¤‡é›‘ãªæŒ‡ç¤ºã®å®Ÿè¡ŒãŠã‚ˆã³è¨ˆç”»ã€ãƒ„ãƒ¼ãƒ«é€£æºæ©Ÿèƒ½ãŒå‘ä¸Šã—ã€ã‚ˆã‚Šå„ªã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½“é¨“ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã¨ã®ã“ã¨ã§ã€æœ¬è¨˜äº‹ã§ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ã´ã£ãŸã‚Šã®ãƒ¢ãƒ‡ãƒ«ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ãã®ä»–ã€ç”»åƒç”Ÿæˆã‚„ TTS ã«ã‚‚ä»Šå¾Œå¯¾å¿œäºˆå®šï¼ˆç¾åœ¨ã¯æ—©æœŸã‚¢ã‚¯ã‚»ã‚¹ã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã®ã¿ï¼‰ã¨ã®è¨˜è¿°ã‚‚ã‚ã‚Šã€ã¾ã™ã¾ã™æœŸå¾…ãŒè†¨ã‚‰ã¿ã¾ã™ã€‚

- [Introducing Gemini 2.0: our new AI model for the agentic era](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#ceo-message)
- [The next chapter of the Gemini era for developers](https://developers.googleblog.com/en/the-next-chapter-of-the-gemini-era-for-developers/)
- [Gemini 2.0 (experimental)](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2)


# MCP ã¨ã¯
MCP ã¯æ§˜ã€…ãªãƒ„ãƒ¼ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨ LLM ã®é–“ã®æ¨™æº–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æä¾›ã™ã‚‹æ„å›³ã§é–‹ç™ºã•ã‚ŒãŸã‚‚ã®ã§ã€ãƒ‡ãƒã‚¤ã‚¹ã¨å‘¨è¾ºæ©Ÿå™¨ã‚’æ¥ç¶šã™ã‚‹æ™‚ã® USB-C ãƒãƒ¼ãƒˆã®ã‚ˆã†ãªå½¹å‰²ã‚’æœãŸã™ã¨ç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ï¼ˆ[Model Context Protocol](https://modelcontextprotocol.io/introduction)ï¼‰ã€‚
ã¾ãŸã€ã™ã§ã«æ§˜ã€…ãªè¨˜äº‹ã§ã‚‚è¨€åŠã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ¨™æº–åŒ–ã™ã‚‹ãŸã‚ã«ã‚‚ä½¿ãˆã‚‹ã‚‚ã®ã§ã™ã€‚

- [Claudeã®MCPã‚’å¾¹åº•è§£èª¬ï¼ & gpt-4o+MCP+YouTube APIã®å‹•ç”»æ¨è–¦ãƒãƒ£ãƒƒãƒˆAIã‚‚ä½œã‚‹](https://qiita.com/sakasegawa/items/b091ad9931cea378099b)


# æœ¬è¨˜äº‹ã§è©¦ã™ã“ã¨
ãƒ„ãƒ¼ãƒ«é€£æºã‚’è©¦ã™æ™‚ã«ã¯ã€LangChain ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç°¡å˜ã«è¨­å®šã§ãã€ãƒ„ãƒ¼ãƒ«å®Ÿè£…ã‚’æ¯”è¼ƒçš„ã‚·ãƒ³ãƒ—ãƒ«ã«è¨˜è¿°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ˆ[Build an Agent](https://python.langchain.com/docs/tutorials/agents/#installation)ï¼‰ã€‚

LangChain ã‚’ç”¨ã„ã‚‹å ´åˆã€å„ãƒ„ãƒ¼ãƒ«ã®å‡¦ç†ã‚’å€‹åˆ¥ã®é–¢æ•°ã¨ã—ã¦è¨˜è¿°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€ä¼¼ãŸã‚ˆã†ãªå‡¦ç†ã§ã‚ã£ã¦ã‚‚ã€é–‹ç™ºè€…é–“ã§å…±æœ‰ãƒ»å†åˆ©ç”¨ã™ã‚‹éš›ã«æ‰‹é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚ãã“ã§ã€MCP ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ä¸‹è¨˜ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ã®ã‚ˆã†ã« LLM-ãƒ„ãƒ¼ãƒ«é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒå…±é€šåŒ–ã•ã‚Œã€é–‹ç™ºè€…é–“ã§ã®å…±æœ‰ãŒã‚¹ãƒ ãƒ¼ã‚ºã«ãªã‚Šæ—¢å­˜ãƒ„ãƒ¼ãƒ«ã®å†åˆ©ç”¨ãŒå®¹æ˜“ã«ãªã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚


![](/images/articles/gemini-bigquery-mcp/mcp_general_architecture.png)
*[MCP General Architecture](https://modelcontextprotocol.io/quickstart#general-architecture)*

æœ¬è¨˜äº‹ã§ã¯ã€ãƒ›ã‚¹ãƒˆå´ã‚’ LangChain ã‚’åˆ©ç”¨ã—ã¦å®Ÿè£…ã—ãªãŒã‚‰ã€ãƒ„ãƒ¼ãƒ«å®Ÿè£…ã‚’ã•ã‚‰ã«ãƒãƒ¼ã‚¿ãƒ–ãƒ«ã«ã™ã‚‹ãŸã‚ã«ã€MCP ã‚µãƒ¼ãƒãƒ¼ã®å‡¦ç†ã‚’ API åŒ–ã—ã¦åˆ†é›¢ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ„ãƒ¼ãƒ«ã®å†åˆ©ç”¨æ€§ãŒå‘ä¸Šã—ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã« API ã‚’ç«‹ã¦ã‚‹etc.ï¼‰ã€ãƒ›ã‚¹ãƒˆå´ã¨ã‚µãƒ¼ãƒãƒ¼å´ã§åˆ†é›¢ã™ã‚‹ã“ã¨ã§ç’°å¢ƒç®¡ç†ãƒ»ã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ç®¡ç†ãªã©ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«ä¿ã¤ã“ã¨ã«ã¤ãªãŒã‚Šã¾ã™ã€‚ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

![](/images/articles/gemini-bigquery-mcp/current_architecture.png)
*æœ¬è¨˜äº‹ã§è©¦ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£*



# å®Ÿè£…ä¾‹
## ãƒ›ã‚¹ãƒˆå´ã®å®Ÿè£…
Host å´ã§ã¯ã€LangChain ã¨ Gemini ã‚’çµ„ã¿åˆã‚ã›ã€MCP ã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ£ãƒƒãƒˆ UI ã¨ã—ã¦ã¯ã€Streamlit ã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã™ã€‚
ä¸‹è¨˜ãŒãƒãƒ£ãƒƒãƒˆãŠã‚ˆã³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆéƒ¨åˆ†ã®å®Ÿè£…ã§ã€å…¨ä½“çš„ã«æ¨™æº–çš„ãªæ›¸ãæ–¹ã‹ã¨æ€ã„ã¾ã™ã€‚LangChain ã‚’ç”¨ã„ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®šéƒ¨åˆ†ã®ã¿ã‚’å¤‰æ›´ã™ã‚‹ã ã‘ã§åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã‚‹ã®ã§ã€æœ€æ–°ã® Gemini 2.0 Flash ã‚’ä½¿ã†å ´åˆã§ã‚‚ã€`llm = ChatVertexAI(model="gemini-2.0-flash-exp")` ã¨è¨˜è¿°ã™ã‚‹ã ã‘ã§æ¸ˆã¿ã¾ã™ã€‚Vertex AI ã‹ã‚‰åˆ©ç”¨ã™ã‚‹ãŸã‚ã« `ChatVertexAI` ã‚’ä½¿ã£ã¦ã„ã¾ã™ã®ã§ Google Cloud ã®èªè¨¼ã‚’é€šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆ[å‚è€ƒ](https://python.langchain.com/docs/integrations/chat/google_vertex_ai_palm/#credentials)ï¼‰ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ç›®çš„ã«å¿œã˜ã¦ã•ã‚‰ã«è©³ã—ãè¨˜è¿°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ãŒã€ã“ã“ã§ã¯ç°¡æ˜“çš„ãªå†…å®¹ã«ç•™ã‚ã¦ãŠãã¾ã™ã€‚

:::details ãƒãƒ£ãƒƒãƒˆãŠã‚ˆã³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆéƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰
```python
import streamlit as st
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
import vertexai
from langchain_google_vertexai import ChatVertexAI

from mcp_client.tools.manage_bigquery import list_tables, describe_table, execute_query


CUSTOM_SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ”¯æ´ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰åˆ¤æ–­ã—ã¦ã€ã‚‚ã—åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã€
ãã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å–å¾—å†…å®¹ã‚’ã‚ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã‚„å‡ºåŠ›å½¢å¼ã«ã—ãŸä¸Šã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æä¾›ã—ã¦ãã ã•ã„ã€‚
ã‚‚ã—åˆ©ç”¨å¯èƒ½ãŒãªã„å ´åˆã¯ãã®æ—¨ã‚’ä¼ãˆãªãŒã‚‰ã€è‡ªç„¶ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½¿ç”¨ã™ã‚‹è¨€èªã§å›ç­”ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
"""


def initialize():
    st.header("Gemini-BigQuery Agent")
    vertexai.init(project="hogetic-lab-datascience-test", location="us-central1")
    return StreamlitChatMessageHistory(key="chat_messages")


def create_agent():
    tools = [list_tables, describe_table, execute_query]
    prompt = ChatPromptTemplate.from_messages([
        ("system", CUSTOM_SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = ChatVertexAI(temperature=0, model="gemini-2.0-flash-exp")
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        memory=None
    )


def main():
    chat_history = initialize()
    agent = create_agent()

    for chat in chat_history.messages:
        st.chat_message(chat.type).write(chat.content)

    if prompt := st.chat_input(placeholder="ã©ã‚“ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹ã‹æ•™ãˆã¦ãã ã•ã„"):
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)
            response = agent.invoke(
                {"input": prompt, "chat_history": chat_history.messages},
                {"callbacks": [st_cb]},
            )
            st.write(response["output"])

        chat_history.add_messages(
            [
                HumanMessage(content=prompt),
                AIMessage(content=response["output"]),
            ]
        )


if __name__ == "__main__":
    main()
```
:::


æ¬¡ã«ãƒ„ãƒ¼ãƒ«é€£æºéƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰ã§ã™ãŒã€@tool ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä»˜è¨˜ã—ãŸé–¢æ•°ã‚’é€šã—ã¦è¡Œã„ã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ MCP ã‚µãƒ¼ãƒãƒ¼ã¨é€šä¿¡ã‚’è¡Œã„ã¾ã™ã€‚é–¢æ•°ã®å‡¦ç†ã¯å˜ç´”ã§ã™ãŒã€LLM ãŒãƒ„ãƒ¼ãƒ«ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ã—ãç†è§£ã§ãã‚‹ã‚ˆã†ã«ã€é–¢æ•°ã® description ã‚’æ˜ç¢ºã«è¨˜è¿°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

:::details ãƒ„ãƒ¼ãƒ«é€£æºéƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰
```python
import requests

from langchain_core.tools import tool
from langchain_core.pydantic_v1 import BaseModel, Field


class BQListTablesRequest(BaseModel):
    datasets_filter: list[str] = Field(
        description="ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµã‚ŠãŸã„å ´åˆã«ä½¿ç”¨ã—ã€ç‰¹ã«çµã‚‰ãªã„å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã¨æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
    )

@tool(args_schema=BQListTablesRequest)
def list_tables(datasets_filter: list[str]) -> str:
    """
    BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
    BigQueryã‚’ä½¿ã£ãŸä»–ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œã«å…ˆç«‹ã£ã¦ã€ã©ã®ã‚ˆã†ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    "{dataset_id}.{table_id}" ã¨ã„ã†è¨˜è¿°ã§ã€ãƒ†ãƒ¼ãƒ–ãƒ«åã®ä¸€è¦§ãŒè¿”ã•ã‚Œã¾ã™ã€‚
    """
    url = "http://mcpserver:8000/bigquery/list-tables/"
    payload = {"datasets_filter": datasets_filter}
    response = requests.get(url, json=payload)
    response.raise_for_status()
    return response.text


class BQDescribeTableRequest(BaseModel):
    table_name: str = Field(description="èª¬æ˜ã‚’å–å¾—ã—ãŸã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®åå‰")

@tool(args_schema=BQDescribeTableRequest)
def describe_table(table_name: str) -> str:
    """
    BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
    ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œã«å…ˆç«‹ã£ã¦ã€ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—ãƒ»ç¢ºèªã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ãŒè¿”ã•ã‚Œã¾ã™ã€‚
    """
    url = "http://mcpserver:8000/bigquery/describe-table/"
    payload = {"table_name": table_name}
    response = requests.post(url, json=payload)
    response.raise_for_status()
    return response.text


class BQExecuteQueryRequest(BaseModel):
    query: str = Field(description="å®Ÿè¡Œã—ãŸã„ã‚¯ã‚¨ãƒª")

@tool(args_schema=BQExecuteQueryRequest)
def execute_query(query: str) -> str:
    """
    BigQuery ã§ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
    ã“ã®ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œã®å‰ã«ã¯å¿…ãšãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—ãƒ»ç¢ºèªã—ã€ç„¡é§„ãªã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚’é¿ã‘ã¦ãã ã•ã„ã€‚
    ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œçµæœã¯ã€è¡Œã”ã¨ã« JSON ã‚’å«ã‚€ list å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¾ã™ã€‚
    """
    url = "http://mcpserver:8000/bigquery/execute-query/"
    payload = {"query": query}
    response = requests.post(url, json=payload)
    response.raise_for_status()
    return response.text
```
:::

LangChain ã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ã«ã¤ã„ã¦ã¯ã€[ML_Bear æ°ã®æ›¸ç±](https://zenn.dev/ml_bear/articles/0c4272c9dcaba3) ãªã©ãŒè©³ã—ã„ã®ã§ãœã²å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚å°‘ã—æ³¨æ„ã¨ã—ã¦ã€ã“ã“æœ€è¿‘ã¯ã‚ˆã‚ŠæŸ”è»Ÿãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ã‚’è¡Œã„ãŸã„å ´åˆã« LangGraph ã‚‚æ¨å¥¨ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã®ã§ã€å¿…è¦ã«å¿œã˜ã¦ãã®é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚å‚ç…§ãã ã•ã„ã€‚

- [Build an Agent with AgentExecutor (Legacy)](https://python.langchain.com/docs/how_to/agent_executor/)
- [ã¤ãã‚ŠãªãŒã‚‰å­¦ã¶ï¼ç”ŸæˆAIã‚¢ãƒ—ãƒªï¼†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºå…¥é–€](https://www.amazon.co.jp/%E3%81%A4%E3%81%8F%E3%82%8A%E3%81%AA%E3%81%8C%E3%82%89%E5%AD%A6%E3%81%B6%EF%BC%81%E7%94%9F%E6%88%90AI%E3%82%A2%E3%83%97%E3%83%AA%EF%BC%86%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88%E9%96%8B%E7%99%BA%E5%85%A5%E9%96%80-Compass-Data-Science-ML_Bear/dp/4839985022)
- [LangGraph](https://python.langchain.com/docs/concepts/architecture/#langgraph)
- [How to migrate from legacy LangChain agents to LangGraph](https://python.langchain.com/docs/how_to/migrate_agent/)


## ã‚µãƒ¼ãƒãƒ¼å´ã®å®Ÿè£…
ã‚µãƒ¼ãƒãƒ¼å´ã§ã¯å„ãƒ„ãƒ¼ãƒ«ã®å‡¦ç†ã®å®Ÿæ…‹ã‚’å«ã¿ã€FastAPI ã‚’ç”¨ã„ã¦ API ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ç”¨æ„ã—ã¾ã™ã€‚BigQuery ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯ã€ä»Šå›ã¯ [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers?tab=readme-ov-file) ã«ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ãŸ MCP ã‚µãƒ¼ãƒãƒ¼ã®1ã¤ã§ã‚ã‚‹ [BigQuery MCP Server](https://github.com/LucasHild/mcp-server-bigquery) ãŒä½¿ã„ã‚„ã™ãã†ã ã£ãŸãŸã‚ã€ã“ã¡ã‚‰ã‚’è‹¥å¹²å¤‰æ›´ã—ãŸä¸Šã§ä½¿ç”¨ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã¯ã€BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ `/bigquery/list-tables`ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—ã™ã‚‹ `/bigquery/describe-table`ã€SQL ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ `/bigquery/execute-query` ã®3ã¤ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚
ä¸‹è¨˜ãŒã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆéƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰ã§ã™ãŒã€MCP ã‚µãƒ¼ãƒãƒ¼ã‚’å‘¼ã¶å‡¦ç†ã¯å…±é€šã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã”ã¨ã«ã‚µãƒ¼ãƒãƒ¼åã‚„å¤‰æ•°ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚


:::details ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆéƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰
```python
import asyncio
from typing import Any

from fastapi import APIRouter
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from app.schemas import BQListTablesRequest, BQDescribeTableRequest, BQExecuteQueryRequest

router = APIRouter()


async def async_request(name: str, server_command: str, server_script: str, req: Any = None):
    server_params = StdioServerParameters(
        command=server_command, args=server_script, env=None
    )
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            result = await session.call_tool(
                name=name,
                arguments=req.dict() if req is not None else {},
            )
            return result.content[0].text


@router.get("/bigquery/list-tables")
def list_tables(req: BQListTablesRequest) -> str:
    return asyncio.run(
        async_request(
            name="list-tables",
            server_command="python",
            server_script=["/src/app/bigquery_manager/server.py"],
            req=req,
        )
    )


@router.post("/bigquery/describe-table")
def describe_table(req: BQDescribeTableRequest) -> str:
    return asyncio.run(
        async_request(
            name="describe-table",
            server_command="python",
            server_script=["/src/app/bigquery_manager/server.py"],
            req=req,
        )
    )


@router.post("/bigquery/execute-query")
def execute_query(req: BQExecuteQueryRequest) -> str:
    return asyncio.run(
        async_request(
            name="execute-query",
            server_command="python",
            server_script=["/src/app/bigquery_manager/server.py"],
            req=req,
        )
    )
```
:::


MCP ã‚µãƒ¼ãƒãƒ¼éƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å‰è¿°ã® [BigQuery MCP Server](https://github.com/LucasHild/mcp-server-bigquery) ã‚’æ´»ç”¨ã—ãŸãŸã‚å®Ÿè£…ã®æ‰‹é–“ã¯ã»ã¼ã‹ã‹ã£ã¦ã„ã¾ã›ã‚“ã€‚

:::details MCP ã‚µãƒ¼ãƒãƒ¼éƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰
```python
import os
from google.cloud import bigquery
import logging
import asyncio
from dotenv import load_dotenv
from mcp.server.models import InitializationOptions
import mcp.types as types
from mcp.server import NotificationOptions, Server
import mcp.server.stdio
from typing import Any

load_dotenv()

# Set up logging to both stdout and file
logger = logging.getLogger('mcp_bigquery_server')
handler_stdout = logging.StreamHandler()
handler_file = logging.FileHandler('/tmp/mcp_bigquery_server.log')

# Set format for both handlers
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler_stdout.setFormatter(formatter)
handler_file.setFormatter(formatter)

# Add both handlers to logger
logger.addHandler(handler_stdout)
logger.addHandler(handler_file)

# Set overall logging level
logger.setLevel(logging.DEBUG)

logger.info("Starting MCP BigQuery Server")

class BigQueryDatabase:
    def __init__(self, project: str, location: str):
        """Initialize a BigQuery database client"""
        if not project:
            raise ValueError("Project is required")
        if not location:
            raise ValueError("Location is required")

        self.client = bigquery.Client(project=project, location=location)

    def execute_query(self, query: str, params: dict[str, Any] | None = None) -> list[dict[str, Any]]:
        """Execute a SQL query and return results as a list of dictionaries"""
        logger.debug(f"Executing query: {query}")
        try:
            if params:
                job = self.client.query(query, job_config=bigquery.QueryJobConfig(query_parameters=params))
            else:
                job = self.client.query(query)
                
            results = job.result()
            rows = [dict(row.items()) for row in results]
            logger.debug(f"Query returned {len(rows)} rows")
            return rows
        except Exception as e:
            logger.error(f"Database error executing query: {e}")
            raise
    
    def list_tables(self, datasets_filter: list[str] = None) -> list[str]:
        """List all tables in the BigQuery database"""
        logger.debug("Listing all tables")

        if datasets_filter:
            datasets = [self.client.dataset(dataset) for dataset in datasets_filter]
        else:
            datasets = list(self.client.list_datasets())

        logger.debug(f"Found {len(datasets)} datasets")

        tables = []
        for dataset in datasets:
            dataset_tables = self.client.list_tables(dataset.dataset_id)
            tables.extend([
                f"{dataset.dataset_id}.{table.table_id}" for table in dataset_tables
            ])

        logger.debug(f"Found {len(tables)} tables")
        return tables

    def describe_table(self, table_name: str) -> list[dict[str, Any]]:
        """Describe a table in the BigQuery database"""
        logger.debug(f"Describing table: {table_name}")

        parts = table_name.split(".")
        if len(parts) != 2:
            raise ValueError(f"Invalid table name: {table_name}")

        dataset_id = parts[0]
        table_id = parts[1]

        query = f"""
            SELECT ddl
            FROM {dataset_id}.INFORMATION_SCHEMA.TABLES
            WHERE table_name = @table_name;
        """
        return self.execute_query(query, params=[
            bigquery.ScalarQueryParameter("table_name", "STRING", table_id),
        ])

async def main(project: str, location: str):
    logger.info(f"Starting BigQuery MCP Server with project: {project} and location: {location}")

    #db = BigQueryDatabase(project, location, datasets_filter)
    db = BigQueryDatabase(project, location)
    server = Server("bigquery-manager")

    # Register handlers
    logger.debug("Registering handlers")

    @server.list_tools()
    async def handle_list_tools() -> list[types.Tool]:
        """List available tools"""
        return [
            types.Tool(
                name="execute-query",
                description="Execute a SELECT query on the BigQuery database",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "SELECT SQL query to execute using BigQuery dialect"},
                    },
                    "required": ["query"],
                },
            ),
            types.Tool(
                name="list-tables",
                description="List all tables in the BigQuery database",
                inputSchema={
                    "type": "object",
                    "properties": {},
                },
            ),
            types.Tool(
                name="describe-table",
                description="Get the schema information for a specific table",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "table_name": {"type": "string", "description": "Name of the table to describe (e.g. my_dataset.my_table)"},
                    },
                    "required": ["table_name"],
                },
            ),
        ]

    @server.call_tool()
    async def handle_call_tool(
        name: str, arguments: dict[str, Any] | None
    ) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:
        """Handle tool execution requests"""
        logger.debug(f"Handling tool execution request: {name}")

        try:
            if name == "list-tables":
                results = db.list_tables(arguments["datasets_filter"])
                return [types.TextContent(type="text", text=str(results))]

            elif name == "describe-table":
                if not arguments or "table_name" not in arguments:
                    raise ValueError("Missing table_name argument")
                results = db.describe_table(arguments["table_name"])
                return [types.TextContent(type="text", text=str(results))]

            if name == "execute-query":
                results = db.execute_query(arguments["query"])
                return [types.TextContent(type="text", text=str(results))]

            else:
                raise ValueError(f"Unknown tool: {name}")
        except Exception as e:
            return [types.TextContent(type="text", text=f"Error: {str(e)}")]

    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        logger.info("Server running with stdio transport")
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="bigquery",
                server_version="0.2.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )


if __name__ == "__main__":
    asyncio.run(
        main(
            project=os.getenv("PROJECT_ID"),  # project_id ã‚’æŒ‡å®šã™ã‚‹
            location=os.getenv("LOCATION"),  # location ã‚’æŒ‡å®šã™ã‚‹
        )
    )
```
:::


# åˆ©ç”¨ä¾‹
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã®æ§˜å­ãŒä¸‹è¨˜ã®ç”»åƒã«ãªã‚Šã¾ã™ï¼ˆå‹•ç”»ãŒã‚µã‚¤ã‚ºã‚ªãƒ¼ãƒãƒ¼ã ã£ãŸãŸã‚ç”»åƒã«ãªã‚Šã¾ã™ï¼‰ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã€`bigquery-public-data` ã® `google_trends` ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã€è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® `test_dataset` ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ç½®ã„ã¦ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç°¡æ˜“ã§ã‚ã‚‹ãŸã‚æ”¹å–„ã®ä½™åœ°ãŒã‚ã£ãŸã‚Šå‡ºåŠ›çµæœã‚‚æ¤œè¨¼ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ãŒã€Gemini 2.0 Flash ãªã‚‰ã§ã¯ã®é«˜é€Ÿãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã‚µã‚¯ã‚µã‚¯é€²ã‚€ã®ã¯ã‹ãªã‚Šè‰¯ã„ä½“æ„Ÿã§ã—ãŸã€‚ã¾ãŸã€ã“ã‚Œã¾ã§ Gemini 1.5 Flash ã§ã¯ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒæ„å›³é€šã‚Šã«å‹•ã‹ãªã„ã“ã¨ãŒã‚ã£ãŸã®ã§ã™ãŒã€ãã†ã„ã£ãŸã“ã¨ã¯ãªãæ„å›³é€šã‚Šã«å‹•ä½œã§ãã¦ã„ã¾ã™ã€‚


![](/images/articles/gemini-bigquery-mcp/demo1.png)
*ãƒ‡ãƒ¢ç”»é¢1*


![](/images/articles/gemini-bigquery-mcp/demo2.png)
*ãƒ‡ãƒ¢ç”»é¢2*


# ã¾ã¨ã‚
LLM ã‹ã‚‰ BigQuery ã‚’å‘¼ã³å‡ºã™ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ã¤ã„ã¦ã€Gemini ã‚·ãƒªãƒ¼ã‚ºã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ Gemini 2.0 Flash ãŠã‚ˆã³ MCP ã‚’åˆ©ç”¨ã—ãŸå®Ÿè£…ä¾‹ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚Gemini 2.0 Flash ã®é«˜é€Ÿãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ˆã‚Šãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å«ã‚€æ©Ÿèƒ½ã«ã¤ã„ã¦ã‚‚å°æ°—å‘³ã‚ˆãæ¤œè¨¼ã‚’é€²ã‚ã‚‰ã‚Œã€ä»Šå¾Œåˆ©ç”¨å¯èƒ½ã«ãªã‚‹äºˆå®šã®ç”»åƒç”Ÿæˆã‚„ TTS ã‚‚çµ„åˆã›ã¦ã‚ˆã‚Šå¤šå½©ãªå¿œç”¨ãŒå¯èƒ½ã«ãªã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ã¾ãŸ MCP ã«ã‚ˆã£ã¦ã€å…±æœ‰ãƒ»è»¢ç”¨ã‚’ã—ã‚„ã™ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒå®¹æ˜“ã«ãªã‚‹ã¨ã¨ã‚‚ã«ã€æ¨™æº–åŒ–ã®æµã‚Œã‚’æ´»ã‹ã—ãŸ [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers?tab=readme-ov-file) ã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«å®Ÿè£…ã®æä¾›ã®å ´ãŒå¢—ãˆã‚‹ã“ã¨ã‚‚æœŸå¾…ã•ã‚Œã¾ã™ã€‚ã§ãã‚‹ã“ã¨ãŒã•ã‚‰ã«å¢—ãˆã¦æ¥½ã—ããªã‚Šã¾ã™ã­ï¼æœ¬è¨˜äº‹ãŒä½•ã‹ã®å½¹ã«ç«‹ã¦ã°å¹¸ã„ã§ã™ã€‚