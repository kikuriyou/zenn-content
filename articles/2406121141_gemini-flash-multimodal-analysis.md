---
title: "Gemini 1.5 Flashã§ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åˆ†æã‚’è©¦ã™"
emoji: "ğŸ€"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["googlecloud", "vertexai", "gemini", "vlm", "ai"]
published: true
publication_name: hogeticlab
---

# ã¯ã˜ã‚ã«

ã“ã“æ•°ãƒ¶æœˆã®é–“ã«LLMï¼ˆLarge Language Modelï¼‰ã¨ã¨ã‚‚ã«VLMï¼ˆVision Language Modelï¼‰ãŒæ™®åŠã—å§‹ã‚ã¦ãŠã‚Šã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã«ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ï¼ˆImage-to-Textï¼‰ãŒå®¹æ˜“ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¦å› åˆ†æãŒã‚ˆã‚Šæ‰‹è»½ã«è¡Œãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¤ã¤ã‚ã‚Šã¾ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€VLMã¨ã—ã¦Vertex AI Gemini 1.5 Flashã‚’åˆ©ç”¨ã—ã¦ã€æ˜ ç”»ãƒã‚¹ã‚¿ãƒ¼ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã«åŠã¼ã™å½±éŸ¿ã®åˆ†æã‚’è©¦ã¿ã¾ã™ã€‚

## æœ¬è¨˜äº‹ã®å¯¾è±¡èª­è€…
æœ¬è¨˜äº‹ã§ã¯Gemini, BERT, SHAPã‚’çµ„ã¿åˆã‚ã›ã¦åˆ†æã™ã‚‹ã®ã§ã€è‡ªç„¶è¨€èªå‡¦ç†ã«ã‚ã‚‹ç¨‹åº¦æ…£ã‚Œã¦ã„ãŸã‚Šé–¢å¿ƒã‚’ãŠæŒã¡ã®æ–¹ã«ãŠã™ã™ã‚ã§ã™ã€‚ãã‚Œãã‚Œã®æ‰‹æ³•ã‚„å®Ÿè£…ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€Geminiã¯[ã“ã¡ã‚‰](https://zenn.dev/harappa80/articles/vertexai_gemini)ã€BERTã¯[ã“ã¡ã‚‰](https://zenn.dev/robes/articles/5c1599615290ed)ã€SHAPã¯[ã“ã¡ã‚‰](https://qiita.com/shin_mura/items/cde01198552eda9146b7)ãªã©ã‚’ã”è¦§ãã ã•ã„ã€‚


## åˆ†æã®æ¦‚è¦

ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹è¦å› åˆ†æã¯ã™ã§ã«å¤šãç›®ã«ã—ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ã—ã¦å›å¸°åˆ†æã‚’è¡Œã£ãŸã‚Šã€BERTãªã©ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¨SHAPã‚’çµ„åˆã›ã¦å„ç‰¹å¾´é‡ã®å½±éŸ¿åº¦ã‚’æ¢ã‚‹ã€ã¨ã„ã£ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€Vertex AI Gemini 1.5 Flashã‚’ç”¨ã„ã¦ç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã€ãã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦BERTãŠã‚ˆã³SHAPã«ã‚ˆã‚‹åˆ†æã‚’è¡Œã„ã€ç‰¹å®šæŒ‡æ¨™ã¸ã®å½±éŸ¿åº¦ã®è§£é‡ˆã‚’è©¦ã¿ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€[IMDB Movies Dataset](https://www.kaggle.com/datasets/amanbarthwal/imdb-movies-data)ã‚’ç”¨ã„ã¦ã€æ˜ ç”»ãƒã‚¹ã‚¿ãƒ¼ç”»åƒã®ã©ã®è¦ç´ ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã«å½±éŸ¿ã—ã¦ã„ã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚

![](/images/articles/gemini-flash-multimodal-analysis/analytical_overview.png)
*åˆ†æã‚¤ãƒ¡ãƒ¼ã‚¸*


# åˆ†æ
ä»¥é™ã§ã¯ã€å®Ÿéš›ã«ä½¿ã£ãŸã‚³ãƒ¼ãƒ‰ã¨åˆã‚ã›ã¦åˆ†æã®æµã‚Œã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

## ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯æ¬¡ã®é€šã‚Šã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ä¸­ã«ã¯äºˆæ¸¬ã«æœ‰ç”¨ãã†ãªã‚«ãƒ©ãƒ ãŒå¤šãå«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€ä»Šå›ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®å¤‰æ›ã‚’è©¦ã™ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ãŸã‚ã«ãƒã‚¹ã‚¿ãƒ¼ç”»åƒ(Posterã‚«ãƒ©ãƒ ã®URLã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ç”»åƒãƒ‡ãƒ¼ã‚¿)ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡(Rating, 0~10ã®ç¯„å›²)ã®ã¿ã‚’ä½¿ã†ã“ã¨ã¨ã—ã¾ã™ã€‚

![](/images/articles/gemini-flash-multimodal-analysis/df_head.png)
*ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼*


ç”»åƒãƒ‡ãƒ¼ã‚¿ã¯ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚Šäº‹å‰ã«ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãã¾ã™ã€‚

```python
import os
from pathlib import Path
import urllib
from concurrent.futures import ThreadPoolExecutor

from tqdm import tqdm
import pandas as pd

class CFG:
    input_dir = Path(f"../input")
    image_dir = input_dir / "images"
    csv_path = input_dir / "imdb-movies-dataset.csv"
    concurrent = True
    num_concurrent = 50

def download_file(url, dst_path):
    try:
        with urllib.request.urlopen(url) as web_file:
            with open(dst_path, 'wb') as local_file:
                local_file.write(web_file.read())
    except Exception as e:
        print(f"Error: {e} in URL: {url}")

imdb_df = pd.read_csv(CFG.csv_path)
if not os.path.exists(CFG.image_dir):
    os.makedirs(CFG.image_dir)
urls = imdb_df["Poster"].tolist()

with ThreadPoolExecutor(max_workers=CFG.num_concurrent) as executor:
    futures = [
        executor.submit(
            download_file, url=url, dst_path=str(CFG.image_dir / url.split("/")[-1])
        ) for url in urls
    ]
    [f.result() for f in tqdm(futures, total=len(futures))]
```
    

## ç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ(Image-to-Text)

ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã«å¯¾ã—ã¦Gemini 1.5 Flashã«ã‚ˆã£ã¦ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä»Šå›è©¦ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ã¯1ç”»åƒã‚ãŸã‚Š2-3ç§’ã§ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã§ããŸãŸã‚ã€å‡¦ç†ã¯ã‚µã‚¯ã‚µã‚¯é€²ã¿ã¾ã—ãŸã€‚ä¸€æ–¹ã§ã€ä¸¦è¡Œå‡¦ç†ã‚’è¡ŒãŠã†ã¨ã™ã‚‹ã¨æ„å¤–ã«æ—©ãquotaã«é”ã—ã¦ã—ã¾ã†ãŸã‚ã€å¤§é‡ã®ç”»åƒã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã„ãŸã„å ´åˆã¯quotaã‚„æ‰€è¦æ™‚é–“ã®é…æ…®ã¯å‡ºã¦ããã†ã§ã™ã€‚ã¨ã¯ã„ãˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã§ã“ã®é€Ÿã•ã¯ã‹ãªã‚Šè‰¯ã„ä½“æ„Ÿã ã£ãŸã®ã§ã€è‰²ã€…ãªæ–¹ã«ãŠã™ã™ã‚ã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚
ä¸€ç‚¹æ°—ã«ãªã£ãŸã“ã¨ã¨ã—ã¦ã€APIã®å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ã€äººã®ç›®ã§ã¯å•é¡Œãªã„ã¨æ„Ÿã˜ã‚‰ã‚ŒãŸç”»åƒã§ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆãŒè¡Œãˆãªã„ã“ã¨ãŒã‚ã‚Šã¾ã—ãŸã€‚æ‰±ã„ãŸã„ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦ãã®å½±éŸ¿ãŒç›®ç«‹ã¤ã“ã¨ã‚‚ã‚ã‚Šå¾—ã‚‹ãŸã‚ã€ã“ã®ç‚¹ã¯æ³¨æ„ãŒå¿…è¦ã¨æ„Ÿã˜ã¾ã—ãŸã€‚

**å‚è€ƒ**
- [Vertex AI ã§ã®ç”Ÿæˆ AI ã®å‰²ã‚Šå½“ã¦ä¸Šé™](https://cloud.google.com/vertex-ai/generative-ai/docs/quotas?hl=ja)
- [Gemini ãƒ¢ãƒ‡ãƒ«ã®é•·æ‰€ã¨åˆ¶é™äº‹é …](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/strengths-limits?hl=ja)
- [Vertex AI ã®æ–™é‡‘](https://cloud.google.com/vertex-ai/generative-ai/pricing?hl=ja)


```python
import os
import re
from pathlib import Path
import pickle
from concurrent.futures import ThreadPoolExecutor

from tqdm import tqdm
import vertexai
from vertexai.generative_models import GenerativeModel, Part, FinishReason
import vertexai.preview.generative_models as generative_models

class CFG:
    model_name = "gemini-1.5-flash-preview-0514"
    temperature = 1
    max_tokens = 1000
    input_dir = Path(f"../input")
    image_dir = input_dir / "images"
    csv_path = input_dir / "imdb-movies-dataset.csv"
    pickle_path = input_dir / "image_captions.pkl"
    concurrent = True
    num_concurrent = 5

def generate(prompt, content_path: str):
    for _ in range(3):
        try:
            vertexai.init(project=os.environ["GOOGLE_CLOUD_PROJECT"], location="us-central1")
            with open(content_path, "rb") as f:
                content = Part.from_data(data=f.read(), mime_type="image/jpeg")
            model = GenerativeModel(CFG.model_name)
            response = model.generate_content(
                [content, prompt],
                generation_config={
                    "max_output_tokens": CFG.max_tokens,
                    "temperature": CFG.temperature,
                    "top_p": 0.95,
                },
                stream=False,
            )
            return response.text
        except Exception as e:
            print(f"Error: {e} in the content of {content_path}")
    return ""
        

imdb_df = pd.read_csv(CFG.csv_path)
image_files = [str(CFG.image_dir / url.split("/")[-1]) for url in imdb_df["Poster"].tolist()]

prompt = textwrap.dedent(
    """\
    Please provide a concise description of the image, focusing on the following:

    - Avoid proper nouns and numbers.
    - Mention the image's atmosphere, appeal, and distinctive features.
    """
)

with ThreadPoolExecutor(max_workers=CFG.num_concurrent) as executor:
    futures = [
        executor.submit(generate, prompt=prompt, content_path=image_file)
        for image_file in image_files
    ]
    image_captions = [f.result() for f in tqdm(futures, total=len(futures))]

with open(CFG.pickle_path, mode='wb') as f:
    pickle.dump(image_captions, f)
```


å…ƒã®ãƒã‚¹ã‚¿ãƒ¼ç”»åƒã¨ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã„ãã¤ã‹ç¢ºèªã—ã¦ã¿ã¾ã™ã€‚ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¯ã„ãšã‚Œã‚‚ã€ç‰¹ã«å•é¡Œãªãç”»åƒã®æå†™ã‚„ç‰¹å¾´ã‚’çš„ç¢ºã«èª¬æ˜ã§ãã¦ã„ã‚‹ã¨æ„Ÿã˜ã‚‰ã‚Œã¾ã™ã€‚


![](/images/articles/gemini-flash-multimodal-analysis/blown_away.jpg)
*The image is a movie poster with a dark and intense atmosphere. The poster features two close-up images of men's faces, one with a yellow hue, the other with a red hue. The men appear to be yelling and engaged in a tense confrontation. The title of the movie is large and bold, printed in white letters on a black background, highlighting the dramatic nature of the film. \n"*


![](/images/articles/gemini-flash-multimodal-analysis/minari.jpg)
*The image portrays a family of four walking hand-in-hand across a grassy field, bathed in soft sunlight. They are casually dressed in comfortable attire, suggesting a sense of warmth and togetherness. A faint American flag in the background adds a subtle note of patriotism. The image exudes a heartwarming and nostalgic atmosphere, appealing to viewers with its portrayal of familial love and simple pleasures. The focus on the family's interconnectedness through their shared walk and the presence of a young child in their midst add a sense of innocence and hope to the composition. \n*


## ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ

æ¬¡ã«ã€Gemini 1.5 Flashã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦BERT([google-bert/bert-base-cased](https://huggingface.co/google-bert/bert-base-cased))ã‚’ç”¨ã„ã¦ã€5epochsã»ã©Finetuningã‚’è¡Œã„ã¾ã™ã€‚å‚è€ƒã®ãŸã‚ã«ã‚³ãƒ¼ãƒ‰ã‚‚è¼‰ã›ã¦ã„ã¾ã™ãŒé•·ã„ã®ã§èª­ã¿é£›ã°ã—ã¦æ§‹ã„ã¾ã›ã‚“ã€‚å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãã¡ã‚“ã¨æ¢ç´¢ã—ãŸã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€Finetuningã«ã‚ˆã£ã¦æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹RMSEãŒ1.07ç¨‹åº¦ã«ãªã£ãŸãŸã‚å­¦ç¿’ã§ããŸã‚‚ã®ã¨åˆ¤æ–­ã—æ¬¡ã®ãƒ—ãƒ­ã‚»ã‚¹ã«é€²ã¿ã¾ã™ã€‚


:::details ã‚³ãƒ¼ãƒ‰
```python
import os
import re
from pathlib import Path
import time
import datetime
import pytz
import pickle
import random

from tqdm.auto import tqdm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.metrics import root_mean_squared_error
import torch
from torch import nn
from torch.cuda import amp
from torch.utils.data import Dataset, DataLoader
import transformers
from transformers import BertTokenizer, BertModel, BertConfig, AdamW
import wandb

class CFG:
    input_dir = Path("../input")
    image_dir = input_dir / "images"
    csv_path = input_dir / "imdb-movies-dataset.csv"
    pickle_path = input_dir / "image_captions.pkl"
    model_dir = "../model"
    num_sample = None  # None, 100
    text_col = "image_caption"
    target_col = "Rating"
    model_name = "google-bert/bert-base-cased"
    num_workers = 4
    batch_size = 32
    n_epoch = 5
    lr = 5e-5
    max_length = 500
    num_warmup_steps = 0
    n_fold = 5
    val_folds = [0]
    use_fp16 = False
    wandb = True
    seed = 42

def class_to_dict(obj):
    return {key: value for key, value in obj.__dict__.items() if not key.startswith('__')}
    
    
def set_seed(seed):
    torch.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.cuda.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)

class NLPDataset(Dataset):
    def __init__(self, df, tokenizer, is_train=True, max_len=128):
        self.texts = df[CFG.text_col].tolist()
        self.targets = df[CFG.target_col].values
        self.tokenizer = tokenizer
        self.is_train = is_train
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, ix):
        sentence = str(self.texts[ix])
        target = self.targets[ix]
        text_inputs = self.tokenizer(
            sentence,
            max_length=self.max_len, 
            padding="max_length", 
            truncation=True,
        )
        data = {
            "input_ids": torch.tensor(text_inputs["input_ids"], dtype=torch.long),
            "target": torch.tensor(target, dtype=torch.float),
        }
        return data

class NLPModel(nn.Module):
    def __init__(self):
        super(NLPModel, self).__init__()
        self.bert = BertModel.from_pretrained(CFG.model_name)
        self.fc = nn.Linear(768, 1)
        torch.nn.init.normal_(self.fc.weight, std=0.02)
    
    def forward(self, input_ids):
        output = self.bert(
            input_ids=input_ids,
            output_attentions=True,
        )
        last_hidden_state = output["last_hidden_state"]
        emb = last_hidden_state[:, 0, :]
        emb = emb.view(-1, 768)

        output = self.fc(emb)
        return output

def train_one_epoch(model, loss_fn, data_loader, optimizer, device, scheduler, epoch, scaler=None):
    epoch_loss = 0
    epoch_data_num = len(data_loader.dataset)

    model.train()
    for step, batch in tqdm(enumerate(data_loader), total=len(data_loader)):
        batch = {k : v.to(device) for k, v in batch.items()}
        input_ids = batch["input_ids"]
        targets = batch["target"]

        optimizer.zero_grad()
        with torch.set_grad_enabled(True):
            with amp.autocast(enabled=CFG.use_fp16):
                preds = model(input_ids)
                loss = loss_fn(preds.squeeze(), targets.squeeze())
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            scheduler.step()
            epoch_loss += loss.item()

        if CFG.wandb:
            wandb.log({
                'step': step + epoch*len(data_loader),
                'train_loss': loss,
                'lr': scheduler.get_lr()[0],
            })
    
    epoch_loss_per_data = epoch_loss / epoch_data_num
    return epoch_loss_per_data

def valid_one_epoch(model, loss_fn, data_loader, device):
    epoch_loss = 0
    epoch_data_num = len(data_loader.dataset)
    pred_list = []
    target_list = []

    model.eval()
    for step, batch in tqdm(enumerate(data_loader), total=len(data_loader)):
        batch = {k : v.to(device) for k, v in batch.items()}
        input_ids = batch["input_ids"]
        targets = batch["target"]
        
        with torch.no_grad():
            preds = model(input_ids)
            loss = loss_fn(preds.squeeze(), targets.squeeze())
            epoch_loss += loss.item()

        pred_list.append(preds.detach().cpu().numpy())
        target_list.append(targets.detach().cpu().numpy())

    epoch_loss_per_data = epoch_loss / epoch_data_num
    val_preds = np.concatenate(pred_list, axis=0)
    val_targets = np.concatenate(target_list, axis=0)
    return epoch_loss_per_data, val_preds, val_targets

def train(train_df, valid_df, exec_time, fold):
    set_seed(CFG.seed)
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"train run device : {device}")

    model = NLPModel()
    model.to(device)
    tokenizer = BertTokenizer.from_pretrained(CFG.model_name)
    scaler = amp.GradScaler(enabled=CFG.use_fp16)

    train_dataset = NLPDataset(train_df, tokenizer, max_len=CFG.max_length, is_train=True)
    valid_dataset = NLPDataset(valid_df, tokenizer, max_len=CFG.max_length, is_train=False)
    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, num_workers=CFG.num_workers, shuffle=True, drop_last=True)
    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, num_workers=CFG.num_workers, shuffle=False)

    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr)
    num_training_steps = int(len(train_loader) * CFG.n_epoch)
    scheduler = transformers.get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=CFG.num_warmup_steps,
        num_training_steps=num_training_steps
    )
    loss_fn = nn.MSELoss()

    iteration = 1
    epoch_train_loss = 0.0
    epoch_val_loss = 0.0
    valid_period = 1

    results_list = []
    val_preds_list = []
    old_model_save_path = None
    score_old = 9999

    for epoch in range(CFG.n_epoch):
        train_epoch_loss = train_one_epoch(
            model, loss_fn, train_loader, optimizer, device, scheduler, epoch=epoch, scaler=scaler
        )
        valid_epoch_loss, val_preds, val_targets = valid_one_epoch(
            model, loss_fn, valid_loader, device
        )
        val_score = root_mean_squared_error(val_targets, val_preds)
        print(f"{epoch=}, {val_score=}")

        lr = optimizer.param_groups[0]['lr']
        results = {
            "epoch": epoch + 1,
            "lr": lr,
            "train_loss": train_epoch_loss,
            "valid_loss": valid_epoch_loss,
            "score": val_score
        }
        print(results)
        results_list.append(results)
        
        if CFG.wandb:
            wandb.log(results)

        msg = f"[Epoch: {epoch+1}/{CFG.n_epoch}] val_loss={valid_epoch_loss:.4f}, val_score={val_score:.2f}"
        print(msg)

        if val_score < score_old:
            msg = "val_score is updated, save the model."
            print(msg)
            model_save_path = f'{CFG.model_dir}/{exec_time}/model_best_score_fold-{fold}.pth'
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
            }, model_save_path)
            score_old = val_score

    return val_score, results_list, val_preds

df = pd.read_csv(CFG.csv_path)
with open(CFG.pickle_path, mode='br') as f:
    image_captions = pickle.load(f)

# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§ããªã‹ã£ãŸç”»åƒã‚„æ¬ æãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
df["image_caption"] = image_captions
df = df[df["image_caption"]!=""].reset_index(drop=True)
df = df[df["Rating"].notnull()].reset_index(drop=True)

exec_time = datetime.datetime.now(pytz.timezone('Asia/Tokyo')).strftime('%Y%m%d-%H%M%S')
ckpt_path = Path(CFG.model_dir) / Path(exec_time)
if not os.path.exists(ckpt_path):
    os.makedirs(ckpt_path)
print(f'exec_time: {exec_time}')

if CFG.wandb:
    wandb.login()

folds = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)
oof_preds = np.zeros((len(df), 1))
val_scores = []

print(f"CV starts, val_folds: {CFG.val_folds}")
for fold, (trn_idx, val_idx) in enumerate(folds.split(df)):
        # ç°¡ç•¥åŒ–ã®ãŸã‚1foldã®ã¿
    if fold not in CFG.val_folds:
        break
    print(f"Fold: {fold}")

    if CFG.wandb:
        project = "image-shap"
        wandb.init(
            project=project,
            config=class_to_dict(CFG),
            name=f"{exec_time}_fold_{fold}",
            group=f'{exec_time}_{project}',
            job_type="train",
            anonymous="must",
        )

    train_df = df.iloc[trn_idx].reset_index(drop=True)
    valid_df = df.iloc[val_idx].reset_index(drop=True)
    val_score, score_list, val_preds = train(train_df, valid_df, exec_time, fold)
    val_scores.append(val_score)
    oof_preds[val_idx] = val_preds

    if CFG.wandb:
        wandb.finish()

print(f"CV end.")
```
:::

## ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã¨SHAPã‚’ç”¨ã„ã¦è¦å› åˆ†æ

ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ä¸‹è¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã¨SHAPå€¤ãŒè¨ˆç®—ã•ã‚Œã€æ–‡ç« ã”ã¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã¸ã®å¯„ä¸åº¦ã‚’è¡¨ã™å›³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚SHAPå€¤ã®è¨ˆç®—ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ä»Šå›ã¯ç°¡æ˜“çš„ã«10ä»¶ã«çµã£ã¦ã„ã¾ã™ãŒã€ä»¶æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§çµæœã‚„ç²¾åº¦ã«ã‚‚å½±éŸ¿ãŒå‡ºã‚‹ã“ã¨ã«ã”æ³¨æ„ãã ã•ã„ã€‚

```python
import shap

def f(sentences):
    input_ids = torch.tensor([tokenizer.encode(text, max_length=CFG.max_length, padding="max_length", truncation=True,) for text in sentences]).to(device)
    with torch.no_grad():
        output = model(input_ids)
    return output.detach().cpu()

explainer = shap.Explainer(model=f, masker=tokenizer, output_names=["Rating"])

shap_values = explainer(df["image_caption"].sample(n=10, random_state=CFG.seed))
shap.plots.text(shap_values)
```


è¡¨ç¤ºã•ã‚Œã‚‹å›³ã§ã¯ã€æ–‡ç« ã”ã¨ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã«å¯¾ã—ã¦æ­£ã®å¯„ä¸ãŒã‚ã‚‹å ´åˆã«èµ¤ã€è² ã®å¯„ä¸ãŒã‚ã‚‹å ´åˆã«é’ã€ã•ã‚‰ã«ãã®å¯„ä¸åº¦ãŒå¤§ãã„ã»ã©é•·ãè¡¨ç¤ºã•ã‚Œã‚‹ã€ã¨ã„ã£ãŸè¦‹æ–¹ã«ãªã‚Šã¾ã™ã€‚å›³ã®ä¸‹éƒ¨ã«ã¯å…ƒã®æ–‡ç« ã‚‚è¡¨ç¤ºã•ã‚Œã¦ãŠã‚Šã€å¯„ä¸åº¦ã®å¤§ãã„ç®‡æ‰€ã«èµ¤è‰²ã¾ãŸã¯é’è‰²ãŒä»˜ä¸ã•ã‚Œã¾ã™ã€‚

ã¾ãš1ã¤ç›®ã®çµæœã«ã¤ã„ã¦ã€`which is both jarring and powerful , drawing attention to the man ' s suffering and the film ' s unsettling subject matter .` ã¨ã„ã†éƒ¨åˆ†ãŒæ­£ã®å¯„ä¸ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ä¸€æ–¹ã§ã€`The atmosphere of the image is dark` ã¯è² ã®å¯„ä¸ãŒã‚ã‚‹ã¨ã®èª¬æ˜ã«ãªã£ã¦ã„ã¾ã™ã€‚æš—ã„é›°å›²æ°—ãŒã‚ã‚Šã¤ã¤ã‚‚ç”·æ€§ã®ãƒ¯ã‚¤ãƒ«ãƒ‰ãªæå†™ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã«åŠ¹ã„ã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ã§ã—ã‚‡ã†ã‹ã€‚

![](/images/articles/gemini-flash-multimodal-analysis/shap_1.png)
*æ–‡ç« ã®å„ç®‡æ‰€ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã¸ã®å¯„ä¸åº¦â‘ *

![](/images/articles/gemini-flash-multimodal-analysis/dog_pound.jpg)
*å…ƒç”»åƒâ‘ *


æ¬¡ã®çµæœã«ç§»ã‚Šã¾ã™ã€‚ã“ã®ç”»åƒãŠã‚ˆã³æ–‡ç« ã«ãŠã„ã¦ã¯ã€`A small , metallic object rests on the ground in front of them , adding to the mysterious and eerie atmosphere` ã€ã•ã‚‰ã«ã¯ `dread , and vulnerability . The young person ' s posture and the ominous symbol behind them create a sense of impending danger` ã¨ã„ã†ç®‡æ‰€ãŒæ­£ã®å¯„ä¸ã‚’ç¤ºã—ã¦ã„ã¦ã€ä¸æ°—å‘³ãªé›°å›²æ°—ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã«åŠ¹ã„ã¦ã„ã‚‹ã“ã¨ãŒä¼ºãˆã¾ã™ã€‚

![](/images/articles/gemini-flash-multimodal-analysis/shap_2.png)
*æ–‡ç« ã®å„ç®‡æ‰€ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã¸ã®å¯„ä¸åº¦â‘¡*

![](/images/articles/gemini-flash-multimodal-analysis/wish_upon.jpg)
*å…ƒç”»åƒâ‘¡*


# çµ‚ã‚ã‚Šã«

æœ¬è¨˜äº‹ã§ã¯åˆ†æã®ã–ã£ãã‚Šã¨ã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä¼ãˆã‚‹ãŸã‚ã«å®Ÿè£…ã‚„è¨­å®šã‚’ç°¡å˜ã«ç•™ã‚ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®æ¥­å‹™é©ç”¨ã«ã‚ãŸã£ã¦ã¯ã„ãã¤ã‹æ„è­˜ã™ã‚‹ã¹ãç‚¹ãŒã‚ã‚Šã¾ã™ã€‚

**Image-to-Textã§é©åˆ‡ãªæƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´**
ä»Šå›ã¯ç°¡å˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§è©¦ã—ã¾ã—ãŸãŒã€åˆ†æã®ç›®çš„ã‚„è¦³ç‚¹ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç·´ã‚‹ã“ã¨ã§å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡ºã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ãã®çµæœã€SHAPã«ã‚ˆã‚‹è¦å› åˆ†æã§ç¾ã‚Œã‚‹æ–‡ç« ç¾¤ã‚‚æ¥­å‹™ã§æ´»ç”¨ã—ã‚„ã™ã„å†…å®¹ã«ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚
**ç”»åƒä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨**
å†’é ­ã§ã‚‚è§¦ã‚ŒãŸã‚ˆã†ã«ã€IMDBã®ãƒ‡ãƒ¼ã‚¿ã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼è©•ä¾¡ã«é–¢ã‚ã‚‹æœ‰ç”¨ã¨æ€ã‚ã‚Œã‚‹ã‚«ãƒ©ãƒ ãŒå¤šãå«ã¾ã‚Œã¾ã™ã€‚ä»Šå›ã¯Image-to-Textã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãŠä¼ãˆã™ã‚‹ç›®çš„ã§çœãã¾ã—ãŸãŒã€å®Ÿéš›ã«ã¯ã“ã‚Œã‚‰ã‚’è€ƒæ…®ã—ã¦åˆ†æã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
**æ–‡ç« åŒå£«ã®ç›¸äº’ä½œç”¨**
ä¸Šè¨˜ã§ç´¹ä»‹ã—ãŸå¯è¦–åŒ–ã¯1æ¬¡å…ƒã«æŠ•å½±ã•ã‚ŒãŸã‚‚ã®ã«ãªã£ã¦ã„ã¾ã™ãŒã€BERTã¯ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ã‚„å…¨çµåˆãŒå«ã¾ã‚Œã‚‹ãŸã‚ã€æ–‡ç« ã‚„å˜èªåŒå£«ã®ç›¸äº’ä½œç”¨ã‚’ç„¡è¦–ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚NNãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ã®ã¯é›£ã—ã„ã‚‚ã®ã®ã€shapãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å†…ã®ä»–ã®å¯è¦–åŒ–æ‰‹æ³•ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã‚‚å½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
**ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ãƒã‚¤ã‚¢ã‚¹ã®è€ƒæ…®**
ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆçµæœã«æ„å›³ã›ãšãƒã‚¤ã‚¢ã‚¹ãŒå«ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚è©³ã—ãã¯[Responsible AI practices](https://ai.google/responsibility/responsible-ai-practices/)ç­‰ã‚’å‚ç…§ã„ãŸã ããŸã„ã§ã™ãŒã€åˆ†æçµæœã‚’ã¾ã¨ã‚ã‚‹éš›ã«ã¯ãƒã‚¤ã‚¢ã‚¹å¯èƒ½æ€§ã®è€ƒæ…®ãŒå¿…è¦ã§ã™ã€‚

ã¾ãŸã€éå»ã®ä¼¼ãŸäº‹ä¾‹ã¨ã—ã¦ã€åºƒå‘Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã®é ˜åŸŸã§ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¯„ä¸åº¦åˆ†æã‚’è¡Œã„ã€ãã®çµæœã‚’ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ä½œæˆã«æ´»ç”¨ã—ãŸ[äº‹ä¾‹](https://www.thinkwithgoogle.com/intl/ja-jp/marketing-strategies/automation/ml_creative/)ãŒã‚ã‚Šã¾ã™ã€‚ä»Šå›ã¯ç”»åƒãƒ‡ãƒ¼ã‚¿ã®è¦ç´ ã‚’æŠ½å‡ºã—ã¦ã„ã‚‹ã®ã§ã€ãã®çµæœã‚’ä½¿ã£ã¦ç”»åƒã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã®ä½œæˆã‚„Text-to-Imageã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å½¹ç«‹ã¦ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ãã®ä»–ã®å¿œç”¨ä¾‹ã¨ã—ã¦ã€Gemini 1.5 Flashã¯Video-to-Textã®å¤‰æ›ã‚‚è¡Œãˆã‚‹ãŸã‚å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŒæ§˜ã®åˆ†æã‚’è©¦ã™ã®ã‚‚å¯èƒ½ã‹ã¨æ€ã„ã¾ã™ã€‚
ä»¥ä¸Šã€ç°¡å˜ã§ã¯ã‚ã‚Šã¾ã™ãŒã€Vertex AI Gemini 1.5 Flashã‚’æ´»ç”¨ã—ãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã®è¦å› åˆ†æã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚ä½•ã‹ã®å‚è€ƒã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

# å‚è€ƒæ–‡çŒ®

- [IMDB Movies Dataset](https://www.kaggle.com/datasets/amanbarthwal/imdb-movies-data)
- [Vertex AI ã§ã®ç”Ÿæˆ AI ã®å‰²ã‚Šå½“ã¦ä¸Šé™](https://cloud.google.com/vertex-ai/generative-ai/docs/quotas?hl=ja)
- [Gemini ãƒ¢ãƒ‡ãƒ«ã®é•·æ‰€ã¨åˆ¶é™äº‹é …](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/strengths-limits?hl=ja)
- [Vertex AI ã®æ–™é‡‘](https://cloud.google.com/vertex-ai/generative-ai/pricing?hl=ja)
- [SHAP(SHapley Additive exPlanation)ã«ã¤ã„ã¦ã®å‚™å¿˜éŒ²](https://qiita.com/perico_v1/items/fbbb18681ecc362a4f9e)
- [Emotion classification multiclass example](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Emotion%20classification%20multiclass%20example.html)
- [æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è§£é‡ˆã™ã‚‹æŒ‡æ¨™SHAPã‚’è‡ªç„¶è¨€èªå‡¦ç†ã«å¯¾ã—ã¦ä½¿ã£ã¦ã¿ãŸ](https://qiita.com/m__k/items/87cf3e4acf414408bfed)
- [åºƒå‘Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–åˆ†é‡ã«ã‚‚é€²ã‚€æ©Ÿæ¢°å­¦ç¿’ã®æµ¸é€](https://www.thinkwithgoogle.com/intl/ja-jp/marketing-strategies/automation/ml_creative/)
- [Responsible AI practices](https://ai.google/responsibility/responsible-ai-practices/)